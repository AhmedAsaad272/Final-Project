from imutils import paths
import matplotlib.pyplot as plt
import random
import pickle
import cv2
import os
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.feature import hog
import numpy as np
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.cluster import MiniBatchKMeans, KMeans

# initialize the data and labels
print("[INFO] loading images...")

train_path = r'C:\My Fieles\Sem1 2020-2021\Machine Vision\Assignment\3\Dataset\training'

# grab the image paths and randomly shuffle them
import os

trainPaths = sorted(list(paths.list_images(train_path)))
random.seed(42)
random.shuffle(trainPaths)

sift_descriptors= []
# loop over the input images
print("[INFO] extracting SIFT for each image...")
for trainPath in trainPaths:
   # Assuming your images are of equal dimension. If not, you need to resize
    image = imread(trainPath)
    sift = cv2.SIFT_create()
    kp, des = sift.detectAndCompute(image,None)
    #append the descriptors to a list of descriptors
    sift_descriptors.append(des)
    
sift_descriptors=np.array(sift_descriptors, dtype="object")
sift_descriptors=np.concatenate(sift_descriptors, axis=0)
#with the descriptors detected, lets clusterize them
print("Training kmeans")
n_clust = 1000
kmeans = MiniBatchKMeans(n_clusters=n_clust, random_state=0).fit(sift_descriptors)


#extracting features, clustring and histogram for training dataset

bag_of_word_train = []
trainlabels = []

# loop over the input images
print("[INFO] extracting SIFT for each image...")
for trainPath in trainPaths:
   # Assuming your images are of equal dimension. If not, you need to resize
    image = imread(trainPath)
    sift = cv2.SIFT_create()
    kp, des = sift.detectAndCompute(image,None)
    #classification of all descriptors in the model
    predict_kmeans=kmeans.predict(des)
    #calculates the histogram
    hist, bin_edges=np.histogram(predict_kmeans, bins=n_clust)
    #histogram is the feature vector
    bag_of_word_train.append(hist)
    # extract the class label from the image path and update the
    # labels list
    label = trainPath.split(os.path.sep)[-2]
    trainlabels.append(label)

# squeeze the list into a numpy array
bag_of_word_train = np.squeeze(bag_of_word_train)

# convert the list into a numpy array
trainlabels = np.array(trainlabels)

import sklearn
from sklearn import preprocessing

# normalize the data
#bag_of_word_train = preprocessing.normalize(bag_of_word_train, norm='l2')
#bag_of_word_train = preprocessing.scale(bag_of_word_train)

#Extracting features , clustring and constructing histogram for testing dataset

print("[INFO] loading images...")
test_path = r'C:\My Fieles\Sem1 2020-2021\Machine Vision\Assignment\3\Dataset\testing'
testpaths= sorted(list(paths.list_images(test_path)))
random.seed(43)
random.shuffle(testpaths)

bag_of_word_test = []
testlabels = []

print("[INFO] extracting SIFT for each image...")
for testpath in testpaths:
    image=imread(testpath)
    sift=cv2.SIFT_create()
    kp, des =sift.detectAndCompute(image,None)
    
    #classification of all descriptors in the model
    predect_kmeans=kmeans.predict(des)
    hist, bin_edges=np.histogram(predict_kmeans, bins=n_clust)
    #histogram is the feature vector
    bag_of_word_test.append(hist)
    # extract the class label from the image path and update the labels list
    label = testpath.split(os.path.sep)[-2]
    testlabels.append(label)
    
# squeeze the list into a numpy array
bag_of_word_test = np.squeeze(bag_of_word_test)

# convert the list into a numpy array
testlabels = np.array(testlabels)

# normalize the data
#bag_of_word_test  = preprocessing.normalize(bag_of_word_test , norm='l2')

import matplotlib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# training a linear SVM
lin_svm = SVC(kernel = 'linear', C=1E10).fit(bag_of_word_train, trainlabels)

lin_svm_predicted_mc = lin_svm.predict(bag_of_word_test)
lin_confusion_mc = confusion_matrix(testlabels, lin_svm_predicted_mc)
df_cm = pd.DataFrame(lin_confusion_mc, 
                     index = [i for i in range(0,5)], columns = [i for i in range(0,5)])
                    
                    
plt.figure(figsize=(5.5,4))
sns.heatmap(df_cm, annot=True)
plt.title('SVM Linear Kernel \nAccuracy:{0:.3f}'.format(accuracy_score(testlabels, 
                                                                       lin_svm_predicted_mc)))
plt.ylabel('True label')
plt.xlabel('Predicted label')


import pylab as pl
from sklearn.metrics import confusion_matrix, accuracy_score #sreeni

def showconfusionmatrix(cm):
    pl.matshow(cm)
    pl.title('Confusion matrix')
    pl.colorbar()
    pl.show()


accuracy = accuracy_score(testlabels, lin_svm_predicted_mc)
print ("accuracy = ", accuracy)
cm = confusion_matrix(testlabels, lin_svm_predicted_mc)
print (cm)

showconfusionmatrix(cm)


from sklearn.metrics import classification_report

print('\n Classification report for Linear SVM\n\n\n',
      classification_report(testlabels, lin_svm_predicted_mc))
      
      
# SVM with Radial Basis Function (RBF) 
svm = SVC(kernel = 'rbf', gamma='auto').fit(bag_of_word_train, trainlabels)
svm_predicted_mc = svm.predict(bag_of_word_test)
confusion_mc = confusion_matrix(testlabels, svm_predicted_mc)
df_cm = pd.DataFrame(confusion_mc, index = [i for i in range(0,5)],
                  columns = [i for i in range(0,5)])

plt.figure(figsize = (5.5,4))
sns.heatmap(df_cm, annot=True)
plt.title('SVM RBF Kernel \nAccuracy:{0:.3f}'.format(accuracy_score(testlabels, 
                                                                    svm_predicted_mc)))
plt.ylabel('True label')
plt.xlabel('Predicted label');


print('\n Classification report for SVM with RBF kernel\n\n\n', 
      classification_report(testlabels, svm_predicted_mc))
